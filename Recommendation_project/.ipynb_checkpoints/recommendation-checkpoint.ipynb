{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb49969-ac2c-4c15-81f2-3b273d47eee9",
   "metadata": {},
   "source": [
    "# Project: Product Recommendation Model\n",
    "\n",
    "Goal: Predict the probability a user will purchase a product → rank products for personalized recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c05cffc-cc5f-4ec0-80b5-799798ed09f3",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Dataset: Olist Brazilian E-Commerce (Kaggle).\n",
    "Period: 2016–2018.\n",
    "Rows: 99K orders, 113K items, 33K products, 96K users.\n",
    "Merged tables: orders, items, products, customers, reviews, category translations.\n",
    "Engineered features (11): price, product rating/reviews, user spend/rating, recency, clicked (1 if purchased), category (one-hot).\n",
    "Target: purchased (1 = bought).\n",
    "Negatives: 3× random non-purchased pairs.\n",
    "Final size: ~450K rows, ~25% positive.\n",
    "Real transactional data with RFM signals; ideal for purchase prediction and top-N recommendations.\n",
    "\n",
    "Here is link to ccess it : https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7b19b9-12d8-468d-9e7e-7d130c2fbcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (3.7)\n",
      "Requirement already satisfied: protobuf in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (4.25.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (75.1.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (4.66.5)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: webencodings in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from bleach->kaggle) (24.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\christian ishimwe\\anaconda3\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02afbc15-85b2-452b-bfd4-cb1acb5bd779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'brazilian-ecommerce.zip', 'kaggle.json', 'recommendation.ipynb']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'brazilian-ecommerce.zip',\n",
       " 'kaggle.json',\n",
       " 'recommendation.ipynb']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())\n",
    "os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58e9618e-b5ff-4456-b875-62782a28a312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Create .kaggle directory\n",
    "os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
    "\n",
    "# Move kaggle.json to ~/.kaggle\n",
    "shutil.copy(\"kaggle.json\", os.path.expanduser(\"~/.kaggle/kaggle.json\"))\n",
    "\n",
    "# Set permissions\n",
    "os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c671c6-3dcd-4031-a023-79b6dea1ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce\n",
      "License(s): CC-BY-NC-SA-4.0\n",
      "brazilian-ecommerce.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d olistbr/brazilian-ecommerce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4389007-835e-4a89-915a-7c7d7651d345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['olist_customers_dataset.csv', 'olist_geolocation_dataset.csv', 'olist_orders_dataset.csv', 'olist_order_items_dataset.csv', 'olist_order_payments_dataset.csv', 'olist_order_reviews_dataset.csv', 'olist_products_dataset.csv', 'olist_sellers_dataset.csv', 'product_category_name_translation.csv']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Extract ZIP contents into 'olist_data' folder\n",
    "with zipfile.ZipFile(\"brazilian-ecommerce.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"olist_data\")\n",
    "\n",
    "# Confirm extracted files\n",
    "print(\"Extracted files:\", os.listdir(\"olist_data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dca21c-355c-44b2-b57a-5ba50698dbb4",
   "metadata": {},
   "source": [
    "# Load & Merge the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fe244bd-bedb-4aca-ba93-efb3308bc4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load core tables from the extracted folder\n",
    "orders        = pd.read_csv('olist_data/olist_orders_dataset.csv')\n",
    "order_items   = pd.read_csv('olist_data/olist_order_items_dataset.csv')\n",
    "products      = pd.read_csv('olist_data/olist_products_dataset.csv')\n",
    "customers     = pd.read_csv('olist_data/olist_customers_dataset.csv')\n",
    "reviews       = pd.read_csv('olist_data/olist_order_reviews_dataset.csv')\n",
    "category_name = pd.read_csv('olist_data/product_category_name_translation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2770a0dd-5187-4975-86fb-6ec645a16d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (113314, 33)\n",
      "                           order_id  order_item_id  \\\n",
      "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
      "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
      "2  000229ec398224ef6ca0657da4fc703e              1   \n",
      "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
      "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
      "\n",
      "                         product_id                         seller_id  \\\n",
      "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
      "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
      "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
      "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
      "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
      "\n",
      "   shipping_limit_date   price  freight_value  \\\n",
      "0  2017-09-19 09:45:35   58.90          13.29   \n",
      "1  2017-05-03 11:05:13  239.90          19.93   \n",
      "2  2018-01-18 14:48:30  199.00          17.87   \n",
      "3  2018-08-15 10:10:18   12.99          12.79   \n",
      "4  2017-02-13 13:57:51  199.90          18.14   \n",
      "\n",
      "                        customer_id order_status order_purchase_timestamp  \\\n",
      "0  3ce436f183e68e07877b285a838db11a    delivered      2017-09-13 08:59:02   \n",
      "1  f6dd3ec061db4e3987629fe6b26e5cce    delivered      2017-04-26 10:53:06   \n",
      "2  6489ae5e4333f3693df5ad4372dab6d3    delivered      2018-01-14 14:33:31   \n",
      "3  d4eb9395c8c0431ee92fce09860c5a06    delivered      2018-08-08 10:00:35   \n",
      "4  58dbd0b2d70206bf40e62cd34e84d795    delivered      2017-02-04 13:57:51   \n",
      "\n",
      "   ... product_length_cm product_height_cm product_width_cm  \\\n",
      "0  ...              28.0               9.0             14.0   \n",
      "1  ...              50.0              30.0             40.0   \n",
      "2  ...              33.0              13.0             33.0   \n",
      "3  ...              16.0              10.0             15.0   \n",
      "4  ...              35.0              40.0             30.0   \n",
      "\n",
      "                          review_id review_score  review_comment_title  \\\n",
      "0  97ca439bc427b48bc1cd7177abe71365          5.0                   NaN   \n",
      "1  7b07bacd811c4117b742569b04ce3580          4.0                   NaN   \n",
      "2  0c5b33dea94867d1ac402749e5438e8b          5.0                   NaN   \n",
      "3  f4028d019cb58564807486a6aaf33817          4.0                   NaN   \n",
      "4  940144190dcba6351888cafa43f3a3a5          5.0                   NaN   \n",
      "\n",
      "                              review_comment_message review_creation_date  \\\n",
      "0     Perfeito, produto entregue antes do combinado.  2017-09-21 00:00:00   \n",
      "1                                                NaN  2017-05-13 00:00:00   \n",
      "2  Chegou antes do prazo previsto e o produto sur...  2018-01-23 00:00:00   \n",
      "3                                                NaN  2018-08-15 00:00:00   \n",
      "4            Gostei pois veio no prazo determinado .  2017-03-02 00:00:00   \n",
      "\n",
      "  review_answer_timestamp  product_category_name_english  \n",
      "0     2017-09-22 10:57:03                     cool_stuff  \n",
      "1     2017-05-15 11:34:13                       pet_shop  \n",
      "2     2018-01-23 16:06:31                furniture_decor  \n",
      "3     2018-08-15 16:39:01                      perfumery  \n",
      "4     2017-03-03 10:54:59                   garden_tools  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge step-by-step\n",
    "df = (order_items\n",
    "      .merge(orders, on='order_id')\n",
    "      .merge(customers, on='customer_id')\n",
    "      .merge(products, on='product_id')\n",
    "      .merge(reviews, on='order_id', how='left')\n",
    "      .merge(category_name, on='product_category_name', how='left'))\n",
    "\n",
    "# Display shape and preview\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ea9c37-565a-4159-9736-84810923aebb",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b42b1b96-e624-4999-b9b7-e218cbf37fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-engineered columns:\n",
      "    price  product_rating_mean  user_total_spend  days_since_last_purchase  \\\n",
      "0   58.90             4.444444             58.90                       355   \n",
      "1  239.90             4.000000            252.78                       349   \n",
      "2  199.00             4.333333            199.00                       231   \n",
      "3   12.99             4.000000             12.99                        25   \n",
      "4  199.90             3.833333            199.90                       575   \n",
      "\n",
      "   clicked  \n",
      "0        1  \n",
      "1        1  \n",
      "2        1  \n",
      "3        1  \n",
      "4        1  \n"
     ]
    }
   ],
   "source": [
    "# Clean & engineer features\n",
    "df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "df['order_approved_at'] = pd.to_datetime(df['order_approved_at'])\n",
    "\n",
    "# Target: purchased = 1 (all in this dataset are purchases → we’ll simulate \"not purchased\")\n",
    "# We'll create negative samples: random user-product pairs that were NOT bought\n",
    "\n",
    "# Aggregations per user\n",
    "user_stats = df.groupby('customer_unique_id').agg(\n",
    "    user_total_spend=('price', 'sum'),\n",
    "    user_num_orders=('order_id', 'nunique'),\n",
    "    user_avg_rating=('review_score', 'mean'),\n",
    "    user_last_purchase=('order_purchase_timestamp', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Aggregations per product\n",
    "product_stats = df.groupby('product_id').agg(\n",
    "    product_price_mean=('price', 'mean'),\n",
    "    product_rating_mean=('review_score', 'mean'),\n",
    "    product_num_reviews=('review_score', 'count'),\n",
    "    product_category=('product_category_name_english', 'first')\n",
    ").reset_index()\n",
    "\n",
    "# Merge stats back\n",
    "df = df.merge(user_stats, on='customer_unique_id').merge(product_stats, on='product_id')\n",
    "\n",
    "# Recency: days since last purchase for this user\n",
    "latest_date = df['order_purchase_timestamp'].max()\n",
    "df['days_since_last_purchase'] = (latest_date - df['user_last_purchase']).dt.days\n",
    "\n",
    "# Click proxy: assume every product in an order was \"seen\" → clicked = 1 for purchased\n",
    "df['clicked'] = 1\n",
    "\n",
    "print(\"Feature-engineered columns:\")\n",
    "print(df[['price', 'product_rating_mean', 'user_total_spend', 'days_since_last_purchase', 'clicked']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deec1e2-cb03-4542-a3c6-66b73813c936",
   "metadata": {},
   "source": [
    "# Generate Negative Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49e79359-e55b-49fa-9bdb-f8bbd57747f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative samples: (339942, 15)\n"
     ]
    }
   ],
   "source": [
    "# Purchased pairs to avoid\n",
    "purchased_pairs = set(zip(df['customer_unique_id'], df['product_id']))\n",
    "n_negatives = len(df) * 3\n",
    "users = df['customer_unique_id'].unique()\n",
    "products = df['product_id'].unique()\n",
    "\n",
    "np.random.seed(42)\n",
    "neg_samples = []\n",
    "while len(neg_samples) < n_negatives:\n",
    "    u = np.random.choice(users)\n",
    "    p = np.random.choice(products)\n",
    "    if (u, p) not in purchased_pairs:\n",
    "        neg_samples.append({'customer_unique_id': u, 'product_id': p, 'purchased': 0})\n",
    "\n",
    "neg_df = pd.DataFrame(neg_samples)\n",
    "neg_df = neg_df.merge(user_stats, on='customer_unique_id', how='left')\n",
    "neg_df = neg_df.merge(product_stats, on='product_id', how='left')\n",
    "\n",
    "# Build modeling columns\n",
    "neg_df['clicked'] = 0\n",
    "neg_df['days_since_last_purchase'] = (latest_date - neg_df['user_last_purchase']).dt.days\n",
    "neg_df['review_score'] = 0\n",
    "\n",
    "# Fill missing\n",
    "fill_dict = {\n",
    "    'days_since_last_purchase': 365,\n",
    "    'user_total_spend': 0,\n",
    "    'user_avg_rating': 3.0,\n",
    "    'product_rating_mean': 3.0,\n",
    "    'product_num_reviews': 0,\n",
    "    'product_price_mean': df['price'].mean()\n",
    "}\n",
    "neg_df = neg_df.fillna(fill_dict)\n",
    "neg_df['category_id'] = neg_df['product_category'].astype('category').cat.codes\n",
    "\n",
    "print(f\"Negative samples: {neg_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fff5fd-53f5-41e2-9c0f-a2c80604db73",
   "metadata": {},
   "source": [
    "# Positive sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a959a80-2cde-4236-a5a5-ac7658a82715",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 19\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Final merge\u001b[39;00m\n\u001b[0;32m     15\u001b[0m common_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_unique_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_price_mean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_rating_mean\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_num_reviews\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_total_spend\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_avg_rating\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays_since_last_purchase\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclicked\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurchased\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 19\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[0;32m     20\u001b[0m     pos_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_price_mean\u001b[39m\u001b[38;5;124m'\u001b[39m})[common_cols],\n\u001b[0;32m     21\u001b[0m     neg_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_price_mean\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_price_mean\u001b[39m\u001b[38;5;124m'\u001b[39m})[common_cols]\n\u001b[0;32m     22\u001b[0m ], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal dataset ready: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpurchased\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts(normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:680\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m         obj_labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39maxes[\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ax]\n\u001b[0;32m    679\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_labels\u001b[38;5;241m.\u001b[39mequals(obj_labels):\n\u001b[1;32m--> 680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m    684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[0;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m    686\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# Positive (purchased = 1)\n",
    "pos_df = df[['customer_unique_id', 'product_id', 'price',\n",
    "             'product_rating_mean', 'product_num_reviews',\n",
    "             'user_total_spend', 'user_avg_rating',\n",
    "             'days_since_last_purchase', 'clicked']].copy()\n",
    "\n",
    "# Use product_price_mean from product_stats for consistency\n",
    "pos_df = pos_df.merge(product_stats[['product_id', 'product_price_mean', 'product_category']], \n",
    "                      on='product_id', how='left')\n",
    "\n",
    "pos_df['purchased'] = 1\n",
    "pos_df['category_id'] = pos_df['product_category'].astype('category').cat.codes\n",
    "\n",
    "# Final merge\n",
    "common_cols = ['customer_unique_id', 'product_id', 'product_price_mean', 'product_rating_mean',\n",
    "               'product_num_reviews', 'user_total_spend', 'user_avg_rating',\n",
    "               'days_since_last_purchase', 'clicked', 'category_id', 'purchased']\n",
    "\n",
    "final_df = pd.concat([\n",
    "    pos_df.rename(columns={'price': 'product_price_mean'})[common_cols],\n",
    "    neg_df.rename(columns={'product_price_mean': 'product_price_mean'})[common_cols]\n",
    "], ignore_index=True)\n",
    "\n",
    "print(f\"Final dataset ready: {final_df.shape}\")\n",
    "print(final_df['purchased'].value_counts(normalize=True).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f896e14-5def-46c7-b40c-7030f69572ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
